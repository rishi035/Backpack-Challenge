**🎒 Backpack Challenge – Clustering & Hyperparameter Tuning**

**📌 Overview**

This repository contains my solution for the Backpack Challenge on Kaggle. In this competition, I explored clustering techniques and hyperparameter tuning to optimize model performance. The goal was to analyze backpack-related data and build a predictive machine learning model and this is a regression prooblem.I achieved my personal best in CatBoost and successfully implemented Bayesian and Optuna hyperparameter tuning for the first time. As a result, I finished in the top 37% of participants. I'm excited about this progress and continuously improving my machine learning skills! 

**🚀 Key Features**

✔️ Feature Engineering: Implementing clustering to create meaningful features.
✔️ Preprocessing Pipelines: Handling missing values, encoding, and scaling.
✔️ Hyperparameter Tuning: Optimizing model with Bayesian and Optuna hyperparameter tuning for CatBoost better accuracy.
✔️ Model Training & Evaluation: Using train-test splits for robust validation.

**📂 Dataset**

The key features include numerical and categorical variables related to backpack characteristics. This was a regression-based competition.

**🛠️ Tech Stack**

🔹 Python (Pandas, NumPy, Matplotlib, Seaborn)
🔹 Machine Learning (Scikit-Learn, CatBoost)
🔹 Clustering (KMeans)
🔹 Google Colab for model training

**📊 Results & Insights**

Utilized clustering techniques to uncover hidden patterns in the dataset.
Optimized CatBoost hyperparameters to enhance model performance.
Handled multiple CSV files efficiently, ensuring seamless data integration.

**📁 Notebook**

Check out the full Jupyter Notebook:
Backpack Challenge Notebook

**🏆 Learnings & Takeaways**

🔹Implemented Bayesian and Optuna hyperparameter tuning for the first time and observed their impact on model performance.
🔹Applied K-Means clustering for the first time in a real-world Kaggle competition, enhancing feature engineering.
🔹Gained experience in handling multiple datasets efficiently within a competition setting


